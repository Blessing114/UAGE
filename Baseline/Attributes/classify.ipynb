{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52da0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "# old = np.load\n",
    "# np.load = lambda *a,**k: old(*a,**k,allow_pickle=True)\n",
    "filename = 'pubmed.npz'\n",
    "with np.load('../tensorflow1.11-graph2gauss/data/'+filename) as loader:\n",
    "# with np.load('test_test.npz') as loader:\n",
    "    loader = dict(loader)\n",
    "    A = sp.csr_matrix((loader['adj_data'], loader['adj_indices'],\n",
    "                       loader['adj_indptr']), shape=loader['adj_shape'])\n",
    "\n",
    "    X = sp.csr_matrix((loader['attr_data'], loader['attr_indices'],\n",
    "                       loader['attr_indptr']), shape=loader['attr_shape'])\n",
    "\n",
    "    z = loader.get('labels')\n",
    "\n",
    "    graph = {\n",
    "        'A': A,\n",
    "        'X': X,\n",
    "        'z': z\n",
    "    }\n",
    "\n",
    "    idx_to_node = loader.get('idx_to_node')\n",
    "    if idx_to_node:\n",
    "        idx_to_node = idx_to_node.tolist()\n",
    "        graph['idx_to_node'] = idx_to_node\n",
    "\n",
    "    idx_to_attr = loader.get('idx_to_attr')\n",
    "    if idx_to_attr:\n",
    "        idx_to_attr = idx_to_attr.tolist()\n",
    "        graph['idx_to_attr'] = idx_to_attr\n",
    "\n",
    "    idx_to_class = loader.get('idx_to_class')\n",
    "    if idx_to_class:\n",
    "        idx_to_class = idx_to_class.tolist()\n",
    "        graph['idx_to_class'] = idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc99145",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, X, z = graph['A'], graph['X'], graph['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e888cb88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jtt_internship/.conda/envs/tensor2py8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/jtt_internship/.conda/envs/tensor2py8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/jtt_internship/.conda/envs/tensor2py8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/jtt_internship/.conda/envs/tensor2py8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/data/jtt_internship/.conda/envs/tensor2py8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro: 0.8414, f1_macro: 0.8416\n",
      "accuracy: 0.8414\n",
      "precision_micro: 0.8414, precision_macro: 0.8428\n",
      "recall_micro: 0.8414, recall_macro: 0.8405\n",
      "average_precision_micro: 0.7613, average_precision_macro: 0.7609\n",
      "roc_auc_micro: 0.8811, roc_auc_macro: 0.8785\n"
     ]
    }
   ],
   "source": [
    "f1_micro, f1_macro, accuracy,precision_micro,precision_macro,recall_micro,recall_macro,average_precision_micro,average_precision_macro,roc_auc_micro,roc_auc_macro = score_node_classification(X, z, n_repeat=1, norm=True)\n",
    "print('f1_micro: {:.4f}, f1_macro: {:.4f}'.format(f1_micro, f1_macro))\n",
    "print('accuracy: {:.4f}'.format(accuracy))\n",
    "print('precision_micro: {:.4f}, precision_macro: {:.4f}'.format(precision_micro, precision_macro))\n",
    "print('recall_micro: {:.4f}, recall_macro: {:.4f}'.format(recall_micro, recall_macro))\n",
    "print('average_precision_micro: {:.4f}, average_precision_macro: {:.4f}'.format(average_precision_micro, average_precision_macro))\n",
    "print('roc_auc_micro: {:.4f}, roc_auc_macro: {:.4f}'.format(roc_auc_micro, roc_auc_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c668bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score,accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import label_binarize\n",
    "def score_node_classification(features, z, p_labeled=0.1, n_repeat=10, norm=True):\n",
    "    lrcv = LogisticRegressionCV()\n",
    "\n",
    "    if norm:\n",
    "        features = normalize(features)\n",
    "\n",
    "    trace = []\n",
    "    for seed in range(n_repeat):\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=1 - p_labeled, random_state=seed)\n",
    "        split_train, split_test = next(sss.split(features, z))\n",
    "\n",
    "        lrcv.fit(features[split_train], z[split_train])\n",
    "        predicted = lrcv.predict(features[split_test])\n",
    "        #one-hot multi-class\n",
    "        labels = list(set(z[split_test]))\n",
    "        y_binarize = label_binarize(z[split_test], classes=labels)\n",
    "        predicted_binarize = label_binarize(predicted, classes=labels)\n",
    "\n",
    "        f1_micro = f1_score(z[split_test], predicted, average='micro')\n",
    "        f1_macro = f1_score(z[split_test], predicted, average='macro')\n",
    "        precision_micro = precision_score(z[split_test], predicted, average='micro')\n",
    "        precision_macro = precision_score(z[split_test], predicted, average='macro')\n",
    "        accuracy= accuracy_score(z[split_test], predicted)\n",
    "        recall_micro = recall_score(z[split_test], predicted, average='micro')\n",
    "        recall_macro = recall_score(z[split_test], predicted, average='macro')\n",
    "\n",
    "        average_precision_micro = average_precision_score(y_binarize, predicted_binarize, average='micro')\n",
    "        average_precision_macro = average_precision_score(y_binarize, predicted_binarize, average='macro')\n",
    "        roc_auc_micro = roc_auc_score(y_binarize, predicted_binarize, average='micro', multi_class='ovr')\n",
    "        roc_auc_macro = roc_auc_score(y_binarize, predicted_binarize, average='macro', multi_class='ovr')\n",
    "        \n",
    "        trace.append((f1_micro, f1_macro, accuracy,precision_micro,precision_macro,recall_micro,recall_macro,average_precision_macro,\\\n",
    "            average_precision_micro,roc_auc_micro,roc_auc_macro))\n",
    "    return np.array(trace).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33529a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
